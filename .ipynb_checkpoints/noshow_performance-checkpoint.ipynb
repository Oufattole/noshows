{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import * # Preprocessing, modelling, interpretation, deployment...\n",
    "import pandas as pd # Basic data manipulation\n",
    "import dabl as db # Summary plot\n",
    "from sklearn.model_selection import train_test_split # Data split\n",
    "from sdv.tabular import CopulaGAN, GaussianCopula, CTGAN, TVAE # Synthetic data\n",
    "from sdv.evaluation import evaluate # Evaluate synthetic data\n",
    "import sdmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110527 entries, 0 to 110526\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   PatientId       110527 non-null  float64\n",
      " 1   AppointmentID   110527 non-null  int64  \n",
      " 2   Gender          110527 non-null  object \n",
      " 3   ScheduledDay    110527 non-null  object \n",
      " 4   AppointmentDay  110527 non-null  object \n",
      " 5   Age             110527 non-null  int64  \n",
      " 6   Neighbourhood   110527 non-null  object \n",
      " 7   Scholarship     110527 non-null  int64  \n",
      " 8   Hipertension    110527 non-null  int64  \n",
      " 9   Diabetes        110527 non-null  int64  \n",
      " 10  Alcoholism      110527 non-null  int64  \n",
      " 11  Handcap         110527 non-null  int64  \n",
      " 12  SMS_received    110527 non-null  int64  \n",
      " 13  No-show         110527 non-null  object \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 11.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read and output the top 5 rows\n",
    "original_data = pd.read_csv('KaggleV2-May-2016.csv')\n",
    "original_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataset):\n",
    "    # get month, day name and hour from Start Time after convert\n",
    "    dataset['Appointment_year'] = dataset['AppointmentDay'].dt.year\n",
    "    dataset['Appointment_month'] = dataset['AppointmentDay'].dt.month\n",
    "    dataset['Appointment_day'] = dataset['AppointmentDay'].dt.day\n",
    "    dataset['Appointment_day_name'] = dataset['AppointmentDay'].dt.day_name()\n",
    "    #appointment hour is always 0 so we leave it out\n",
    "    \n",
    "    # get month and day name and hour from Start Time after convert\n",
    "    dataset['Register_year'] = dataset['RegisterDay'].dt.year\n",
    "    dataset['Register_month'] = dataset['RegisterDay'].dt.month\n",
    "    dataset['Register_day'] = dataset['RegisterDay'].dt.day\n",
    "    dataset['Register_day_name'] = dataset['RegisterDay'].dt.day_name()\n",
    "    dataset['Register_hour'] = dataset['RegisterDay'].dt.hour\n",
    "    \n",
    "    dataset['waiting_time'] = (dataset['AppointmentDay']-dataset['RegisterDay']).dt.days\n",
    "    \n",
    "    dataset.drop('AppointmentDay', axis=1, inplace=True)\n",
    "    dataset.drop('RegisterDay', axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "def convert_datetime(dataset):\n",
    "    dataset.rename(columns={'Handcap':'Handicap'},inplace=True)\n",
    "    dataset.rename(columns={\"ScheduledDay\":\"RegisterDay\"},inplace=True)\n",
    "    dataset['AppointmentDay'] = pd.to_datetime(dataset['AppointmentDay']).dt.tz_localize(None)\n",
    "    dataset['RegisterDay'] = pd.to_datetime(dataset['RegisterDay']).dt.tz_localize(None)\n",
    "convert_datetime(original_data)\n",
    "extract_features(original_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split real data into training + test set\n",
    "train, test, target_train, target_test = train_test_split(original_data.drop(\"No-show\", axis = 1), original_data[\"No-show\"], test_size = 0.4, random_state = 42)\n",
    "train[\"No-show\"] = target_train\n",
    "test[\"No-show\"] = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target feature\n",
    "target = \"No-show\"\n",
    "\n",
    "# Continuous/numeric features\n",
    "cont_feats = [\"Age\", \"Appointment_year\",  \"Appointment_month\", \"Appointment_day\",\n",
    "              \"Register_year\", \"Register_month\", \"Register_day\",\n",
    "              \"Register_hour\", \"waiting_time\"]\n",
    "\n",
    "# Ordinal features\n",
    "ord_feats = {}\n",
    "\n",
    "# Categorical geatures\n",
    "cat_feats = [\"Gender\", \"Scholarship\", \"Hipertension\", \n",
    "             \"Diabetes\", \"Alcoholism\", \"Handicap\", \"SMS_received\", \n",
    "             \"Appointment_day_name\", \"Register_day_name\"]\n",
    "\n",
    "# Features to ignore\n",
    "ignore = [\"PatientId\", \"AppointmentID\"]#ignore id variables and datetime type columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup complete!\n"
     ]
    }
   ],
   "source": [
    "setup(train.sample(frac=1), \n",
    "      target = target, \n",
    "      test_data = test,\n",
    "      fold_strategy = \"kfold\",\n",
    "      numeric_features = cont_feats,\n",
    "      categorical_features = cat_feats,\n",
    "      ordinal_features = ord_feats,\n",
    "      ignore_features = ignore,\n",
    "      normalize = True,\n",
    "      normalize_method = \"zscore\",\n",
    "      silent = True, verbose = False)\n",
    "print(\"setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [CopulaGAN, GaussianCopula, CTGAN, TVAE]\n",
    "sample_sizes = [0, 500, 1000, 10_000, 39_362, 70_000, 100_000]\n",
    "metric_classes = sdmetrics.single_table.SingleTableMetric.get_subclasses()\n",
    "classifiers = [\"catboost\", \"dt\"]\n",
    "performance = [\"f1\",\"accuracy\", \"recall\", \"precision\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>BNLogLikelihood</th>\n",
       "      <th>LogisticDetection</th>\n",
       "      <th>SVCDetection</th>\n",
       "      <th>BinaryDecisionTreeClassifier</th>\n",
       "      <th>BinaryAdaBoostClassifier</th>\n",
       "      <th>BinaryLogisticRegression</th>\n",
       "      <th>BinaryMLPClassifier</th>\n",
       "      <th>MulticlassDecisionTreeClassifier</th>\n",
       "      <th>...</th>\n",
       "      <th>CSTest</th>\n",
       "      <th>KSTest</th>\n",
       "      <th>KSTestExtended</th>\n",
       "      <th>ContinuousKLDivergence</th>\n",
       "      <th>DiscreteKLDivergence</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model_name, sample_size, BNLogLikelihood, LogisticDetection, SVCDetection, BinaryDecisionTreeClassifier, BinaryAdaBoostClassifier, BinaryLogisticRegression, BinaryMLPClassifier, MulticlassDecisionTreeClassifier, MulticlassMLPClassifier, LinearRegression, MLPRegressor, GMLogLikelihood, CSTest, KSTest, KSTestExtended, ContinuousKLDivergence, DiscreteKLDivergence, classifier_name, f1, accuracy, recall, precision]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = [\"model_name\"]\n",
    "sample_size_name = [\"sample_size\"]\n",
    "metric_class_names = [str(metric_name) for metric_name in metric_classes]\n",
    "classifier_name = [\"classifier_name\"]\n",
    "performance_names = [\"f1\",\"accuracy\", \"recall\", \"precision\"]\n",
    "columns = model_name + sample_size_name + metric_class_names + classifier_name + performance_names\n",
    "results = pd.DataFrame(columns=columns)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BNLogLikelihood',\n",
       " 'LogisticDetection',\n",
       " 'SVCDetection',\n",
       " 'BinaryDecisionTreeClassifier',\n",
       " 'BinaryAdaBoostClassifier',\n",
       " 'BinaryLogisticRegression',\n",
       " 'BinaryMLPClassifier',\n",
       " 'MulticlassDecisionTreeClassifier',\n",
       " 'MulticlassMLPClassifier',\n",
       " 'LinearRegression',\n",
       " 'MLPRegressor',\n",
       " 'GMLogLikelihood',\n",
       " 'CSTest',\n",
       " 'KSTest',\n",
       " 'KSTestExtended',\n",
       " 'ContinuousKLDivergence',\n",
       " 'DiscreteKLDivergence']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score_column(scores):\n",
    "    score_column = []\n",
    "    for metric in metric_class_names:\n",
    "        if metric in score_aggregate.columns:\n",
    "            score_column.append(score_aggregate[metric])\n",
    "        else:\n",
    "            score_column.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-431d94acb3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrained_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#make sure you have the right column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_sizes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dai/lib/python3.6/site-packages/sdv/tabular/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    118\u001b[0m             LOGGER.debug(\n\u001b[1;32m    119\u001b[0m                 'Fitting %s model to table %s', self.__class__.__name__, self._metadata.name)\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dai/lib/python3.6/site-packages/sdv/tabular/copulagan.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, table_data)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mtable_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ht\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dai/lib/python3.6/site-packages/sdv/tabular/ctgan.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, table_data)\u001b[0m\n\u001b[1;32m     51\u001b[0m         self._model.fit(\n\u001b[1;32m     52\u001b[0m             \u001b[0mtable_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mdiscrete_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategoricals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         )\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dai/lib/python3.6/site-packages/ctgan/synthesizers/ctgan.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[1;32m    353\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizerD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0mpen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                     \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizerD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dai/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/dai/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for initialize_generative_model in models:\n",
    "    model_column = [str(model)]\n",
    "    model = initialize_generative_model()\n",
    "    trained_model = model.fit(data=train)#make sure you have the right column\n",
    "    for sample_size in sample_sizes:\n",
    "        \n",
    "        sample_size_column = [sample_size]\n",
    "        synthetic_data = trained_model.sample(sample_size)\n",
    "        score_aggregate = score(aggregate())\n",
    "        score_column = make_score_column(score_aggregate)\n",
    "        for classifier_name in classifier_names:\n",
    "            classifier_column = [classifier_name]\n",
    "            classifier = create_model(classifier_name) # Create the catboost classifier\n",
    "            pred_holdout = predict_model(classifier)\n",
    "            performance_column = list(pred_holdout[\"F1\", \"Accuracy\", \"Recall\", \"Prec.\"])\n",
    "            results_row = model_column + sample_size_column + score_column + classifier_column + performance_column\n",
    "            results.append(results_row)\n",
    "            count+=1\n",
    "            print(count)\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dai-thon",
   "language": "python",
   "name": "dai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
